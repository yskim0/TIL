## 심층 신경망 성능 향상
> Train/Dev/Test Sets

- 신경망을 훈련시킬 때 고려해야 할 점
    - #layers, #hidden units, learning rates, activation functions
- Idea -> Code -> Experiment -> Idea -> ... 
- 딥러닝에 아주 경험이 많은 사람일지라도 첫 시도에 하이퍼파라미터에 대한 최고의 선택을 하는 것은 힘듦.
- **위의 사이클(I->C->E->I...) 을 얼마나 효율적으로 돌 수 있는지 + 데이터 세트 잘 설정**하는 것이 중요.
#
- Data Set = Training set + "dev" set + test set
    - 현대 빅데이터 시대에는 개발 세트와 테스트 세트가 훨씬 더 작은 비율이 되는 것이 트렌드.
    - 개발 세트와 테스트 세트의 목표는 서로 다른 알고리즘을 시험하고 어떤 알고리즘이 더 잘 작동하는지 확인하기 때문.
    - 예를 들어, 백만 개의 훈련 샘플이 있는 경우 만 개의 샘플을 개발 세트로 하고 만 개의 샘플을 테스트 세트로 하는 **98:1:1**
    - 더 큰 샘플인 경우 **99.5 : 0.25 : 0.25 or 99.5 : 0.4 : 0.1**
    - 상대적으로 적은 데이터 세트일 경우에는 전통적인 비율 6:2:2도 괜찮음.

#
- Mismatched train/test distribution
    - Training set: Cat pics from web.  
    Dev/test sets: Cat pics from users using your app
    - 이 두 가지 데이터의 분포는 달라질 수 있음.  
    **이러한 경우 개발과 테스트 세트 분포가 같은 분포에서 와야 함.**


- 테스트 세트를 갖고 있지 않아도 괜찮긴 함.
    - 테스트 셋의 목표는 최종 네트워크의 성능에 대한 비편향 추정을 제공하는 것.
    - 비편향 추정이 필요 없는 경우 테스트 셋 필요 없음.
    - 개발 세트만 있는 경우 모든 테스트 세트를 훈련 세트에서 훈련시키고 다른 모델 아키텍트를 시도하고 이것을 개발 세트에서 평가... 이 과정 반복
    - 머신러닝에서 별도의 테스트 세트 없이 훈련 세트와 개발 세트만 있는 경우 개발 세트를 테스트 세트라고 부름.
    - 그러나 실제로 하는 것은 테스트 세트를 교차 검증 세트로 사용하는 것!
- dev set == Validation dataset
#

> Bias/Variance

#### high bias : underfitting  
#### just right  
#### high variance : overfitting

- Ex. Cat classification
    - Train set error : 1%
    - Dev set error : 11%
    - **high variance**하다
    - 최적의 오차, 베이지안 오차라고 불리는 베이지안 최적 오차가 0%라고 가정한 것.  
    만약 15%라고 올리면 15 : 16 결과가 합당하고 높은 편향이라 부르지 않고 낮은 분산이 됨.  


    <img width="753" alt="스크린샷 2020-02-01 오전 12 41 47" src="https://user-images.githubusercontent.com/48315997/73587077-0daa5180-44fa-11ea-990c-553c0576e84b.png">


- 훈련 세트 오차를 확인함으로써 최소한 훈련 데이터에서 얼마나 알고리즘이 적합한지 감 잡을 수 있음. (편향 문제가 있는지 알 수 있음)
훈련 세트에서 개발 세트로 갈 때 오차가 얼마나 커지는지에 따라서 분산 문제가 얼마나 나쁜지 감 잡을 수 있음.
훈련 세트에서 개발 세트로 일반화를 잘 하느냐에 따라 분산에 대한 감이 달라짐.
이 모든 것은 베이즈 오차가 꽤 작고 훈련 세트와 개발 세트가 같은 확률 분포에서 왔다는 가정 하에 지켜짐.

#
  
- 매우 높은 차원의 입력에서는 어떤 영역은 높은 편향을 갖고 어떤 영역은 높은 분산을 갖게 됨.
